{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yuzzPHd6gIUQ",
    "outputId": "a34fedfd-7340-43a9-90d7-4952f665db1e"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile \"../openaigpt.py\"\n",
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.expanduser(\"~/.django\") )\n",
    "import my_config\n",
    "from my_config import *\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key=my_config.OPENAPI_KEY\n",
    ")\n",
    "\n",
    "'''response = client.completions.create(\n",
    "    model=\"llama3.2\",\n",
    "    prompt=\"____\",\n",
    "    max_tokens=256\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)\n",
    "'''\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model = \"llama3.2\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\"    , \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\"      , \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\" , \"content\": \"The LA Dodgers won in 2020.\"},\n",
    "    {\"role\": \"user\"      , \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 22:23:28,440 geoapp INFO: OLLAMA_HOST => http://127.0.0.1:11434/v1\n",
      "2024-10-31 22:23:28,461 geoapp INFO: llama3.2 : [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'who won 1996 election'}]\n",
      "2024-10-31 22:23:36,799 httpx INFO: HTTP Request: POST http://127.0.0.1:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The 1996 United States presidential election was held on November 5, 1996. The winners of the presidential election were:\\n\\n* Bill Clinton (Democratic Party) - re-elected as President\\n* Bob Dole (Republican Party) - lost to Bill Clinton in the general election\\n\\nHowever, it's worth noting that Al Gore won the popular vote but lost the electoral college vote to George W. Bush in some states in the 1996 presidential election\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%writefile \"../olgpt.py\"\n",
    "import sys, os, ollama, torch, logging,datetime\n",
    "from ollama import Client\n",
    "from mangorest.mango import webapi\n",
    "sys.path.append(os.path.expanduser(\"~/.django\") )\n",
    "from openai import OpenAI\n",
    "    \n",
    "logger = logging.getLogger( \"geoapp\" )\n",
    "\n",
    "device = \"cpu\"\n",
    "if (torch.cuda.is_available() ):\n",
    "    device = \"cuda\"\n",
    "\n",
    "\n",
    "OLLAMA_HOST= 'http://10.0.0.29:11434/v1'\n",
    "\n",
    "if (os.path.exists(os.path.expanduser(\"~/.django/my_config.py\"))):\n",
    "    import my_config\n",
    "    try:\n",
    "        from my_config import OLLAMA_HOST\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = OLLAMA_HOST,\n",
    "    api_key=my_config.OPENAPI_KEY\n",
    ")\n",
    "\n",
    "OLLAMA = Client(host=OLLAMA_HOST)\n",
    "logger.info(f\"OLLAMA_HOST => {OLLAMA_HOST}\")\n",
    "#--------------------------------------------------------------------------------------------------------    \n",
    "@webapi(\"/gpt/generate/\")\n",
    "def ollma_generate(request=None, model=\"llama3|mistral\", prompt=\"\", stream=True,**kwargs):\n",
    "    logger.info(f\"Prepping: {datetime.datetime.now()}\")\n",
    "    model = model.split(\"|\")[0].strip()\n",
    "    response = OLLAMA.generate(model=model, prompt=prompt, stream=stream)\n",
    "    # Stream response\n",
    "    ret = \"\"\n",
    "    for chunk in response:\n",
    "        data = chunk[\"response\"]\n",
    "        ret += data\n",
    "        \n",
    "    logger.debug(ret)\n",
    "    return ret\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------    \n",
    "@webapi(\"/gpt/openai/\")\n",
    "def openai(request=None, model=\"llama3.2|mistral\", host=\"\", prompt=\"\", messages=\"\", **kwargs):\n",
    "\n",
    "    client = OpenAI( base_url = host or OLLAMA_HOST, api_key  = my_config.OPENAPI_KEY )\n",
    "\n",
    "    tmsg = [\n",
    "                {\"role\": \"system\"    , \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\"      , \"content\": prompt or \"Where was it played?\"}\n",
    "    ]\n",
    "    \n",
    "    messages = messages or tmsg\n",
    "    model    = model.split(\"|\")[0]\n",
    "    \n",
    "    logger.info(f\"{model} : {messages}\")\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model = \"llama3.2\",\n",
    "        messages= tmsg\n",
    "        )\n",
    "\n",
    "    ret = completion.choices[0].message\n",
    "    \n",
    "    return ret.content\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ollma_generate(prompt=\"whos is the chief data scientist of Space Lockheed Martin\", stream=True)   \n",
    "openai(prompt=\"who won 1996 election\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "fg = '''  \n",
    "messages=[\n",
    "    {\"role\": \"system\"    , \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\"      , \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\" , \"content\": \"The LA Dodgers won in 2020.\"},\n",
    "    {\"role\": \"user\"      , \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    "'''\n",
    "\n",
    "#json.loads(fg)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
