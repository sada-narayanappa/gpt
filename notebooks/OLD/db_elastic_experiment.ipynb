{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yuzzPHd6gIUQ",
    "outputId": "a34fedfd-7340-43a9-90d7-4952f665db1e"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ragging using elastic\n",
    "\n",
    "Step 1 is to run elastic image:\n",
    "\n",
    "```md\n",
    "\n",
    "RUN Elastic:\n",
    "\n",
    "    docker network create demonet\n",
    "\n",
    "    export ESI='-p 9200:9200 docker.elastic.co/elasticsearch/elasticsearch:8.16.1'\n",
    "    export ESP='-e ELASTICSEARCH_PASSWORD=elastic -e ELASTICSEARCH_USERNAME=elastic'\n",
    "    export ESS='-e xpack.security.enabled=false -e discovery.type=single-node'\n",
    "    docker run --rm -it --name es01 --network=demonet ${ESS} ${ESP} ${ESI}\n",
    "\n",
    "# Now connect using url http://http://localhost:9200\n",
    "```\n",
    "\n",
    "You may want to adjust some parameters\n",
    "\n",
    "Login to docker as root and install vi\n",
    "\n",
    "```sh\n",
    "[ ]\n",
    "    docker exec -u 0 -it <container es01 /bin/bash\n",
    "    apt-get update\n",
    "    apt-get install vim\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile ../db_elastic.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from typing import Any, Dict, Optional, List\n",
    "from gpt.ollama_embed import get_ollama_embedding\n",
    "\n",
    "def esclient(url = \"http://localhost:9200\", user = 'elastic', pw = \"elastic\"):\n",
    "    es = Elasticsearch(url, basic_auth = (user, pw), verify_certs=0)\n",
    "    es.info()\n",
    "    es.ping()\n",
    "    return es\n",
    "\n",
    "# Create an Elasticsearch index with a mapping for dense vector embeddings.\n",
    "def create_index(es, index_name: str, dims=3064):\n",
    "    if es.indices.exists(index=index_name):\n",
    "        print(f\"Index '{index_name}' already exists. Skipping creation.\")\n",
    "        return\n",
    "\n",
    "    index_body = {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"text\": {\"type\": \"text\"},\n",
    "                \"embedding\": {\n",
    "                    \"type\": \"dense_vector\",\n",
    "                    \"dims\": dims,  # Set dimensions based on your model's embeddings\n",
    "                    \"index\": True,\n",
    "                    \"similarity\": \"cosine\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    es.indices.create(index=index_name, body=index_body)\n",
    "    print(f\"Index '{index_name}' created successfully!\")\n",
    "\n",
    "# Index documents with embeddings\n",
    "def index_documents(es, index_name: str, documents: List[dict]):\n",
    "    for idx, doc in enumerate(documents):\n",
    "        # Generate embedding for the text\n",
    "        embedding = get_ollama_embedding(doc[\"text\"])\n",
    "        document_body = {\n",
    "            \"text\": doc[\"text\"],\n",
    "            \"embedding\": embedding\n",
    "        }\n",
    "        # Index the document\n",
    "        es.index(index=index_name, id=idx, body=document_body)\n",
    "        print(f\"Document {idx} indexed successfully.\")\n",
    "\n",
    "# Main function\n",
    "def example_load(index_name = \"embeddings_index\", dims=3024):\n",
    "    es = esclient()\n",
    "    create_index(es, index_name)\n",
    "\n",
    "    # Example data to index\n",
    "    documents = [\n",
    "        {\"text\": \"Elasticsearch is a powerful search engine for text and vectors.\"},\n",
    "        {\"text\": \"OLLAMA can generate embeddings for semantic search.\"},\n",
    "        {\"text\": \"Combining Elasticsearch with OLLAMA enables vector search.\"},\n",
    "    ]\n",
    "    index_documents(es, index_name, documents)\n",
    "\n",
    "    print(\"All documents indexed successfully.\")\n",
    "\n",
    "#example_load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
