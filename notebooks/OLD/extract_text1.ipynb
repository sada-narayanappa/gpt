{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../extract_text.py\n"
     ]
    }
   ],
   "source": [
    "#%%writefile ../extract_text1.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import sys, os, logging,datetime, hashlib, pandas as pd\n",
    "logger = logging.getLogger( \"geoapp\" )\n",
    "import docx\n",
    "from langchain_core.documents import Document\n",
    "from mangorest.mango import webapi\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# Following functions extract chunks\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def extractDocx(file):\n",
    "    document = docx.Document(file)\n",
    "\n",
    "    # STEP 1: extract tables \n",
    "    tables=[]\n",
    "    for table in document.tables:\n",
    "        data = []\n",
    "        keys = None\n",
    "        for i, row in enumerate(table.rows):\n",
    "            text = (cell.text for cell in row.cells)\n",
    "\n",
    "            if i == 0:\n",
    "                keys = tuple(text)\n",
    "                continue\n",
    "            row_data = dict(zip(keys, text))\n",
    "            data.append(row_data)\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        tables.append(df)\n",
    "\n",
    "    # STEP 2: extract text \n",
    "    paras = []\n",
    "    paraTexts = []\n",
    "    secHeader = \"\"\n",
    "\n",
    "    for para in document.paragraphs:\n",
    "        if (not para.text.strip()):\n",
    "            continue;\n",
    "        \n",
    "        if para.style.name != \"Normal\" and \"Paragraph\" not in para.style.name:\n",
    "            #print(\"==>\", para.style.name)\n",
    "            if ( len(paraTexts) > 0):\n",
    "                paras.append(Document(metadata={\"head\": secHeader, 'source': file}, \n",
    "                                       page_content=\"\\n\".join(paraTexts)))\n",
    "                paraTexts = []\n",
    "\n",
    "            secHeader = para.text \n",
    "            continue;\n",
    "        \n",
    "        paraTexts.append(para.text)\n",
    "\n",
    "    return tables, paras\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def extractPDF(file):\n",
    "    import pdfplumber\n",
    "\n",
    "    docs = []\n",
    "    with pdfplumber.open(file) as doc:\n",
    "        for i, page in enumerate(doc.pages):\n",
    "            #lines = page.extract_text_lines()\n",
    "            #txt = \"\\n\".join([l['text'] for l in lines])\n",
    "            txt = page.extract_text_simple()\n",
    "            meta= dict(source=file, page=1)\n",
    "            docs.append(Document(metadata=meta, page_content=txt))\n",
    "\n",
    "    return [], docs\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def extractTextChunks(file):\n",
    "    tables, paras = [], \"\"\n",
    "    if (file.endswith(\"doc\") or file.endswith(\"docx\") ):\n",
    "        tables, paras =  extractDocx(file)\n",
    "    elif (file.endswith(\"pdf\") ):\n",
    "        tables, paras = extractPDF(file)\n",
    "        #ofile = convertToDoc(file)\n",
    "        #return extractDocx(ofile)\n",
    "    else:\n",
    "        raise (f\"Unknown file type {file}\")        \n",
    "    \n",
    "    return tables, paras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3797 \n",
      "\n",
      " Heading 1\n",
      "This Userâ€™s Manual provides essential data on the Ariane 5 launch System, which together with the Soyuz and Vega launch vehicles, constitutes the European space transportation union. These three launch systems are operated by Arianespace from the\n"
     ]
    }
   ],
   "source": [
    "txts = extractText(file= SAMPLE_DOC)\n",
    "print(len(txts), \"\\n\\n\", txts[0:256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
