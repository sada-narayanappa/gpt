{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Speech to Text\n",
    "\n",
    "This is an example of speech to text modules and using whisper to do transcriptions.\n",
    "\n",
    "In this project we not only transcribe, but also summarize the transcriptions meeting summaries, indeintify speakers etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../whispermod.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"../whispermod.py\"\n",
    "from mangorest.mango import webapi \n",
    "import colabexts\n",
    "from colabexts import jcommon\n",
    "from pytube import YouTube\n",
    "import whisper,  os, datetime, librosa, io, soundfile, sys, hashlib, torch\n",
    "import threading\n",
    "import numpy as np\n",
    "\n",
    "model  = None\n",
    "device = \"cpu\"\n",
    "#-----------------------------models-----------------------------------------------------------------\n",
    "device = \"cpu\"\n",
    "if (torch.cuda.is_available() ):\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "#-----------------------------------------------------------------------------------\n",
    "mutex  = threading.Lock()\n",
    "def getmodel():\n",
    "    global model, mutex\n",
    "    \n",
    "    if model is None:\n",
    "        mutex.acquire()\n",
    "        if model is None:\n",
    "            model = whisper.load_model(\"base\", device=device)\n",
    "        mutex.release()   \n",
    "    return model\n",
    "#-----------------------------------------------------------------------------------\n",
    "def transcribe_file(file =\"/Users/snarayan/Desktop/data/audio/index.mp4\", **kwargs):\n",
    "    result = getmodel().transcribe(file)\n",
    "    return result\n",
    "#-----------------------------------------------------------------------------------\n",
    "def is_video_file(filename):\n",
    "    video_extensions = [\".mp4\", \".avi\", \".mov\", \".mkv\", \".wmv\", \".flv\"] \n",
    "    return os.path.splitext(filename)[1].lower() in video_extensions\n",
    "#-----------------------------------------------------------------------------------\n",
    "def is_audio_file(filename):\n",
    "    audio_extensions = [\".mp3\", \".wav\", \".flac\", \".ogg\", \".aac\", \".m4a\"] \n",
    "    return os.path.splitext(filename)[1].lower() in audio_extensions\n",
    "# ------------------------------------------------------------------------------\n",
    "def transcribe(fn, offset=0, duration=60*60, detectSpeakers=1, **kwargs):\n",
    "    if (type(fn) == str):\n",
    "        data, sample_rate = librosa.load(fn, offset=offset, duration=duration, mono=True, sr=16000)\n",
    "    else:\n",
    "        content = io.BytesIO(fn)\n",
    "        data, sample_rate = librosa.load(content,sr=16000, mono=True, offset=offset, duration=duration)\n",
    "\n",
    "    ret = getmodel().transcribe(data)\n",
    "    for s in ret.get('segments', []):\n",
    "        s.pop('tokens')\n",
    "        if ( detectSpeakers):\n",
    "            speaker = who(data, s.get('start'), s.get('end'), **kwargs)\n",
    "            s['speakers'] = [speaker]\n",
    "\n",
    "    return ret\n",
    "\n",
    "def transcribeWS(request, **kwargs):\n",
    "    for f in request.FILES.getlist('file'):\n",
    "        content = f.read()\n",
    "\n",
    "    ret = transcribe(content, **kwargs)    \n",
    "    print(f\"Transcribed: {ret}\")\n",
    "    return ret\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "@webapi(\"/scribe/convert2wav/\")\n",
    "def convert2wav(request, **kwargs):\n",
    "    for f in request.FILES.getlist('file'):\n",
    "        content = f.read()\n",
    "\n",
    "    content = io.BytesIO(content)\n",
    "    data, sample_rate = librosa.load(content,sr=16000, mono=True, offset=offset, duration=duration)\n",
    "\n",
    "    #offset, duration, file = 0, None, \"/tmp/test1.wav\"\n",
    "    #data, sample_rate = librosa.load(file, offset=offset, duration=duration, mono=True, sr=16000)\n",
    "    ret = io.BytesIO()\n",
    "    soundfile.write(\"/tmp/_tmp.wav\", data, samplerate=16000)\n",
    "    with open(\"/tmp/_tmp.wav\", \"rb\") as f:\n",
    "        ret.write(f.read())\n",
    "    return ret\n",
    "#--------------------------------------------------------------------------------------------------------    \n",
    "test_url = \"https://www.youtube.com/watch?v=DuSDVj9a4WM&list=PLEpvS3HCVQ5_ZlyF1_i-WSwBzLoDLxoc9\"\n",
    "\n",
    "@webapi(\"/scribe/transcribe_youtube/\")\n",
    "def transcribe_youtube( url = test_url , force_download=False, force_transribe=False, **kwargs):    \n",
    "    h = hashlib.md5(url.encode())\n",
    "    file = \"/tmp/\" + str(h.hexdigest()) + \".mp4\"\n",
    "    \n",
    "    if (force_download or not os.path.exists(file)):  \n",
    "        file = YouTube(url).streams.filter(only_audio=True).first().download(filename=file)\n",
    "\n",
    "    print( f\"File: {file}\")\n",
    "    if (force_transribe or not os.path.exists(file +\".txt\")):  \n",
    "        print( f\"Calling transcription: {file}.txt\")\n",
    "        tr = getmodel().transcribe(file)\n",
    "        ret = splitIntoParas(tr)\n",
    "        with open(file +\".txt\", \"w\") as f:\n",
    "            f.write(ret)\n",
    "        with open(file +\".json\", \"w\") as f:\n",
    "            f.write(str(tr))\n",
    "            \n",
    "        transcription = ret\n",
    "    else:\n",
    "        with open(file +\".txt\", \"r\") as f:\n",
    "            transcription = f.read()\n",
    "        \n",
    "    return transcription;\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------    \n",
    "@webapi(\"/scribe/transcribe_media/\")\n",
    "def transcribe_me\n",
    "( request, url=None, force_reload=\"\", **kwargs):    \n",
    "    print(f\"{force_reload} <==========\")\n",
    "    ret  = [] \n",
    "    # STEP 1. extract from file\n",
    "    for f in request.FILES.getlist('file'):\n",
    "        content = f.read()\n",
    "        filename = f\"/tmp/{str(f)}\"\n",
    "        \n",
    "        if ( not (is_video_file(filename) or is_audio_file(filename) ) ):\n",
    "            ret.append (dict(file=filename, trans=f\"{filename}: - not a media file\", segs=\"\") )\n",
    "            continue;\n",
    "        \n",
    "        filename_trans = f\"{filename}.trans\"\n",
    "        filename_segs  = f\"{filename}.segs\"\n",
    "        \n",
    "        if (not force_reload and os.path.exists(filename)):\n",
    "            if (os.path.exists(filename_trans) and os.path.exists(filename_segs) ):\n",
    "                with open(filename_trans) as f:\n",
    "                    trans = f.read()\n",
    "                with open(filename_segs) as f:\n",
    "                    segs = f.read()\n",
    "                    \n",
    "                ret.append (dict(file=filename, trans= trans, segs=segs))\n",
    "            else:\n",
    "                msg = f\"{filename}: file exists! have you initiated transcribe! click force\"\n",
    "                ret.append (dict(file=filename, trans=msg, segs=\"??\") )\n",
    "        else:\n",
    "            with open(filename, \"wb\") as f:\n",
    "                f.write(content)\n",
    "            results = transcribe_file(filename)\n",
    "            txt =\"\"\n",
    "            for t in results['segments']:\n",
    "                o=f\"{t['start']:-7.2f} - {t['end']:7.2f} : {t['text']}\"\n",
    "                txt += o + \"\\n\"\n",
    "            ret.append (dict(file=filename, trans= results['text'], segs=txt))\n",
    "            \n",
    "            with open(filename_trans, \"w\") as f:\n",
    "                f.write(results['text'])\n",
    "            with open(filename_segs, \"w\") as f:\n",
    "                f.write(txt)\n",
    "    \n",
    "    # STEP 2: transcribe youtube URL when it works\n",
    "    \n",
    "    return ret;                \n",
    "\n",
    "#-----------------------------------------------------------------------------------    \n",
    "def process(sysargs):\n",
    "    print(\"Parsing and processing\")\n",
    "    \n",
    "    if (sysargs.url.strip()):\n",
    "        print( f\"Transcribing {sysargs.url}\")\n",
    "        transcribe_youtube(sysargs.url.strip())\n",
    "    \n",
    "#-----------------------------------------------------------------------------------\n",
    "sysargs=None\n",
    "def addargs():\n",
    "    global sysargs\n",
    "    p = argparse.ArgumentParser(f\"{os.path.basename(sys.argv[0])}:\")\n",
    "    p.add_argument('-u', '--url', type=str, default=\"\", help=\"Youtube URL\")\n",
    "    try:\n",
    "        sysargs, unknown=p.parse_known_args(sys.argv[1:])\n",
    "    except argparse.ArgumentError as exc:\n",
    "        print(exc.message )\n",
    "        \n",
    "    if (unknown):\n",
    "        print(\"Unknown options: \", unknown)\n",
    "        #p.print_help()\n",
    "    return sysargs    \n",
    "#-----------------------------------------------------------------------------------\n",
    "if __name__ == '__main__':\n",
    "    if (not colabexts.jcommon.inJupyter()):\n",
    "        t1 = datetime.datetime.now()\n",
    "        sysargs = addargs()\n",
    "        ret = process(sysargs)\n",
    "        t2 = datetime.datetime.now()\n",
    "        print(f\"#All Done in {str(t2-t1)} ***\")\n",
    "    else:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../whispermod.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"../whispermod.py\"\n",
    "from mangorest.mango import webapi \n",
    "import colabexts\n",
    "from colabexts import jcommon\n",
    "from pytube import YouTube\n",
    "import whisper,  os, datetime, librosa, io, soundfile, sys, hashlib\n",
    "import threading\n",
    "import numpy as np\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "def splitIntoParas(tr, nLinesPerPara=4):\n",
    "    n= nLinesPerPara\n",
    "    l=tr.get('segments', [])\n",
    "    ret = \"\"\n",
    "    for i,j in enumerate(l[::n]):\n",
    "        a, b = i*n, i*n + n\n",
    "        o = \"\".join([j['text'] for j in l[a:b]])\n",
    "        ret += o.strip() + \"\\n\\n\";\n",
    "        #print(f'{a}-{b} {o} \\n')\n",
    "        \n",
    "    return ret\n",
    "#-----------------------------------------------------------------------------------\n",
    "def who(data, start=0, end=None, **kwargs):\n",
    "    try:\n",
    "        import scribe.notebooks.speaker as speaker\n",
    "        top3, tops = speaker.whoisInAudio1(data, top=3, start=start, end=end, **kwargs  )\n",
    "        ret =  { \n",
    "            'top3'    : \";\".join(top3[::-1]) ,\n",
    "            'topScore': \"\"+str(tops)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: \" , e)\n",
    "        ret = {'top3': \";;\", 'topScore': 0}\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DuSDVj9a4WM'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_video_id_from_url(video_url):\n",
    "    \"\"\"\n",
    "    Examples:\n",
    "    - http://youtu.be/SA2iWivDJiE\n",
    "    - http://www.youtube.com/watch?v=_oPAwA_Udwc&feature=feedu\n",
    "    - http://www.youtube.com/embed/SA2iWivDJiE\n",
    "    - http://www.youtube.com/v/SA2iWivDJiE?version=3&amp;hl=en_US\n",
    "    \"\"\"\n",
    "    import urllib.parse\n",
    "    url = urllib.parse.urlparse(video_url)\n",
    "    if url.hostname == 'youtu.be':\n",
    "        return url.path[1:]\n",
    "    if url.hostname in ('www.youtube.com', 'youtube.com'):\n",
    "        if url.path == '/watch':\n",
    "            p = urllib.parse.parse_qs(url.query)\n",
    "            return p['v'][0]\n",
    "        if url.path[:7] == '/embed/':\n",
    "            return url.path.split('/')[2]\n",
    "        if url.path[:3] == '/v/':\n",
    "            return url.path.split('/')[2]\n",
    "\n",
    "    return video_url\n",
    "\n",
    "get_video_id_from_url( \"http://www.youtube.com/watch?v=_oPAwA_Udwc&feature=feedu\")\n",
    "test_url = \"https://www.youtube.com/watch?v=DuSDVj9a4WM&list=PLEpvS3HCVQ5_ZlyF1_i-WSwBzLoDLxoc9\"\n",
    "get_video_id_from_url(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/e346104/venv/py312/lib/python3.12/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "/Users/e346104/venv/py312/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ffmpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwhisper\u001b[39;00m\n\u001b[1;32m      3\u001b[0m m\u001b[38;5;241m=\u001b[39mwhisper\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/tmp/test.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/py312/lib/python3.12/site-packages/whisper/transcribe.py:139\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, carry_initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[1;32m    136\u001b[0m     decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Pad 30-seconds of silence to the input audio, for slicing\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m mel \u001b[38;5;241m=\u001b[39m \u001b[43mlog_mel_spectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_mels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_SAMPLES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m content_frames \u001b[38;5;241m=\u001b[39m mel\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m N_FRAMES\n\u001b[1;32m    141\u001b[0m content_duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(content_frames \u001b[38;5;241m*\u001b[39m HOP_LENGTH \u001b[38;5;241m/\u001b[39m SAMPLE_RATE)\n",
      "File \u001b[0;32m~/venv/py312/lib/python3.12/site-packages/whisper/audio.py:140\u001b[0m, in \u001b[0;36mlog_mel_spectrogram\u001b[0;34m(audio, n_mels, padding, device)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(audio):\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(audio, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 140\u001b[0m         audio \u001b[38;5;241m=\u001b[39m \u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     audio \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(audio)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/venv/py312/lib/python3.12/site-packages/whisper/audio.py:58\u001b[0m, in \u001b[0;36mload_audio\u001b[0;34m(file, sr)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# fmt: on\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load audio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py:1955\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1953\u001b[0m     err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1955\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ffmpeg'"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "m=whisper.load_model(\"base\")\n",
    "m.transcribe(\"/tmp/test.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m/tmp/test.wav\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls /tmp/test.wav"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
