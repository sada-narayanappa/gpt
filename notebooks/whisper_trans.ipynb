{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Speech to Text\n",
    "\n",
    "This is an example of speech to text modules and using whisper to do transcriptions.\n",
    "\n",
    "In this project we not only transcribe, but also summarize the transcriptions meeting summaries, indeintify speakers etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../whispermod.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"../whispermod.py\"\n",
    "from mangorest.mango import webapi \n",
    "import colabexts\n",
    "from colabexts import jcommon\n",
    "from pytube import YouTube\n",
    "import whisper,  os, datetime, librosa, io, soundfile, sys, hashlib, torch\n",
    "import numpy as np\n",
    "\n",
    "#-----------------------------models-----------------------------------------------------------------\n",
    "import platform\n",
    "device = \"cpu\"\n",
    "if (torch.cuda.is_available() ):\n",
    "    device = \"cuda\"\n",
    "#elif torch.backends.mps.is_available() and platform.processor() =='arm':\n",
    "#    device = \"mps\"\n",
    "#-----------------------------------------------------------------------------------\n",
    "import threading\n",
    "mutex        = threading.Lock()\n",
    "transcriber  = None\n",
    "def getTranscriber():\n",
    "    global transcriber, mutex, device\n",
    "    \n",
    "    if transcriber is None:\n",
    "        mutex.acquire()\n",
    "        if transcriber is None:\n",
    "            transcriber = whisper.load_model(\"base\", device=device)\n",
    "        mutex.release()   \n",
    "    return transcriber\n",
    "#-----------------------------------------------------------------------------------\n",
    "def transcribe_file(file =\"/Users/snarayan/Desktop/data/audio/index.mp4\", **kwargs):\n",
    "    result = getTranscriber().transcribe(file)\n",
    "    return result\n",
    "#-----------------------------------------------------------------------------------\n",
    "def is_video_file(filename):\n",
    "    video_extensions = [\".mp4\", \".avi\", \".mov\", \".mkv\", \".wmv\", \".flv\"] \n",
    "    return os.path.splitext(filename)[1].lower() in video_extensions\n",
    "#-----------------------------------------------------------------------------------\n",
    "def is_audio_file(filename):\n",
    "    audio_extensions = [\".mp3\", \".wav\", \".flac\", \".ogg\", \".aac\", \".m4a\"] \n",
    "    return os.path.splitext(filename)[1].lower() in audio_extensions\n",
    "# ------------------------------------------------------------------------------\n",
    "def transcribe(fn, offset=0, duration=60*60, detectSpeakers=0, **kwargs):\n",
    "    filename = fn\n",
    "    if (type(fn) == str):\n",
    "        data, sample_rate = librosa.load(fn, offset=offset, duration=duration, mono=True, sr=16000)\n",
    "    else:\n",
    "        filename = \"/tmp/bytes.wav\"\n",
    "        content = io.BytesIO(fn)\n",
    "        data, sample_rate = librosa.load(content,sr=16000, mono=True, offset=offset, duration=duration)\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(fn)\n",
    "\n",
    "    results = getTranscriber().transcribe(filename, word_timestamps=True)\n",
    "    txt =\"\"\n",
    "    for t in results.get('segments', []):\n",
    "        speaker=\"\"\n",
    "        if ( detectSpeakers):\n",
    "            speaker = who(data, t['start'], t['end'], **kwargs)\n",
    "        o=f\"{t['start']:-7.3f} : {t['end']:7.3f} : {speaker} : {t['text']}\"\n",
    "        txt += o + \"\\n\"\n",
    "    ret = dict(file=filename, trans= results['text'], segs=txt)\n",
    "\n",
    "    return ret\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------    \n",
    "@webapi(\"/scribe/transcribe_audio/\")\n",
    "def transcribeAudio(request, **kwargs):\n",
    "    for f in request.FILES.getlist('file'):\n",
    "        content = f.read()\n",
    "\n",
    "    ret = transcribe(content, **kwargs)    \n",
    "    print(f\"Transcribed: {ret}\")\n",
    "    return ret\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "@webapi(\"/scribe/convert2wav/\")\n",
    "def convert2wav(request, **kwargs):\n",
    "    for f in request.FILES.getlist('file'):\n",
    "        content = f.read()\n",
    "\n",
    "    content = io.BytesIO(content)\n",
    "    data, sample_rate = librosa.load(content,sr=16000, mono=True, offset=offset, duration=duration)\n",
    "\n",
    "    #offset, duration, file = 0, None, \"/tmp/test1.wav\"\n",
    "    #data, sample_rate = librosa.load(file, offset=offset, duration=duration, mono=True, sr=16000)\n",
    "    ret = io.BytesIO()\n",
    "    soundfile.write(\"/tmp/_tmp.wav\", data, samplerate=16000)\n",
    "    with open(\"/tmp/_tmp.wav\", \"rb\") as f:\n",
    "        ret.write(f.read())\n",
    "    return ret\n",
    "#--------------------------------------------------------------------------------------------------------    \n",
    "test_url = \"https://www.youtube.com/watch?v=DuSDVj9a4WM&list=PLEpvS3HCVQ5_ZlyF1_i-WSwBzLoDLxoc9\"\n",
    "\n",
    "@webapi(\"/scribe/transcribe_youtube/\")\n",
    "def transcribe_youtube( url = test_url , force_download=False, force_transribe=False, **kwargs):    \n",
    "    h = hashlib.md5(url.encode())\n",
    "    file = \"/tmp/\" + str(h.hexdigest()) + \".mp4\"\n",
    "    \n",
    "    if (force_download or not os.path.exists(file)):  \n",
    "        file = YouTube(url).streams.filter(only_audio=True).first().download(filename=file)\n",
    "\n",
    "    print( f\"File: {file}\")\n",
    "    if (force_transribe or not os.path.exists(file +\".txt\")):  \n",
    "        print( f\"Calling transcription: {file}.txt\")\n",
    "        tr = getTranscriber().transcribe(file)\n",
    "        ret = splitIntoParas(tr)\n",
    "        with open(file +\".txt\", \"w\") as f:\n",
    "            f.write(ret)\n",
    "        with open(file +\".json\", \"w\") as f:\n",
    "            f.write(str(tr))\n",
    "            \n",
    "        transcription = ret\n",
    "    else:\n",
    "        with open(file +\".txt\", \"r\") as f:\n",
    "            transcription = f.read()\n",
    "        \n",
    "    return transcription;\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------    \n",
    "@webapi(\"/scribe/transcribe_media/\")\n",
    "def transcribe_media( request, file=\"\", url=None, force_reload=\"\", **kwargs):    \n",
    "    ret  = [] \n",
    "    # STEP 1. extract from file\n",
    "    for f in request.FILES.getlist('file'):\n",
    "        content = f.read()\n",
    "        filename = f\"/tmp/{str(f)}\"\n",
    "        print(f\"{force_reload} {filename} <==========\")\n",
    "        \n",
    "        if ( not (is_video_file(filename) or is_audio_file(filename) ) ):\n",
    "            ret.append (dict(file=filename, trans=f\"{filename}: - not a media file\", segs=\"\") )\n",
    "            continue;\n",
    "        \n",
    "        filename_trans = f\"{filename}.trans\"\n",
    "        filename_segs  = f\"{filename}.segs\"\n",
    "        \n",
    "        if (not force_reload and os.path.exists(filename)):\n",
    "            if (os.path.exists(filename_trans) and os.path.exists(filename_segs) ):\n",
    "                with open(filename_trans) as f:\n",
    "                    trans = f.read()\n",
    "                with open(filename_segs) as f:\n",
    "                    segs = f.read()\n",
    "                    \n",
    "                ret.append (dict(file=filename, trans= trans, segs=segs))\n",
    "            else:\n",
    "                msg = f\"{filename}: file exists! have you initiated transcribe! click force\"\n",
    "                ret.append (dict(file=filename, trans=msg, segs=\"??\") )\n",
    "        else:\n",
    "            with open(filename, \"wb\") as f:\n",
    "                f.write(content)\n",
    "            results = transcribe_file(filename)\n",
    "            txt =\"\"\n",
    "            for t in results['segments']:\n",
    "                o=f\"{t['start']:-7.2f} : {t['end']:7.2f} : {t['text']}\"\n",
    "                txt += o + \"\\n\"\n",
    "            ret.append (dict(file=filename, trans= results['text'], segs=txt))\n",
    "            \n",
    "            with open(filename_trans, \"w\") as f:\n",
    "                f.write(results['text'])\n",
    "            with open(filename_segs, \"w\") as f:\n",
    "                f.write(txt)\n",
    "    \n",
    "    # STEP 2: transcribe youtube URL when it works\n",
    "    \n",
    "    return ret;                \n",
    "\n",
    "#-----------------------------------------------------------------------------------    \n",
    "def process(sysargs):\n",
    "    print(\"Parsing and processing\")\n",
    "    \n",
    "    if (sysargs.url.strip()):\n",
    "        print( f\"Transcribing {sysargs.url}\")\n",
    "        transcribe_youtube(sysargs.url.strip())\n",
    "    \n",
    "#-----------------------------------------------------------------------------------\n",
    "sysargs=None\n",
    "def addargs():\n",
    "    global sysargs\n",
    "    p = argparse.ArgumentParser(f\"{os.path.basename(sys.argv[0])}:\")\n",
    "    p.add_argument('-u', '--url', type=str, default=\"\", help=\"Youtube URL\")\n",
    "    try:\n",
    "        sysargs, unknown=p.parse_known_args(sys.argv[1:])\n",
    "    except argparse.ArgumentError as exc:\n",
    "        print(exc.message )\n",
    "        \n",
    "    if (unknown):\n",
    "        print(\"Unknown options: \", unknown)\n",
    "        #p.print_help()\n",
    "    return sysargs    \n",
    "#-----------------------------------------------------------------------------------\n",
    "if __name__ == '__main__':\n",
    "    if (not colabexts.jcommon.inJupyter()):\n",
    "        t1 = datetime.datetime.now()\n",
    "        sysargs = addargs()\n",
    "        ret = process(sysargs)\n",
    "        t2 = datetime.datetime.now()\n",
    "        print(f\"#All Done in {str(t2-t1)} ***\")\n",
    "    else:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': '/tmp/bytes.wav',\n",
       " 'trans': \" Hello. Oh, hello. I didn't know you were there. I needed to design. Okay, I heard of deep. This is Diane in New Jersey. I'm Sheila and Texas originally from Chicago. Oh, I'm originally from Chicago also. I'm in New Jersey now though. Well, there's not much difference. At least they all call me a Yankee down here. So we'll come back. I don't hear that in New Jersey now.\",\n",
       " 'segs': \"  6.380 -   6.900 :  :  Hello.\\n  7.640 -   8.720 :  :  Oh, hello.\\n  8.900 -   9.780 :  :  I didn't know you were there.\\n  9.980 -  10.620 :  :  I needed to design.\\n 10.900 -  12.380 :  :  Okay, I heard of deep.\\n 12.540 -  13.980 :  :  This is Diane in New Jersey.\\n 14.400 -  17.500 :  :  I'm Sheila and Texas originally from Chicago.\\n 18.100 -  20.020 :  :  Oh, I'm originally from Chicago also.\\n 20.180 -  21.320 :  :  I'm in New Jersey now though.\\n 21.880 -  23.720 :  :  Well, there's not much difference.\\n 24.120 -  27.260 :  :  At least they all call me a Yankee down here.\\n 27.560 -  28.020 :  :  So we'll come back.\\n 28.020 -  29.800 :  :  I don't hear that in New Jersey now.\\n 29.980 -  29.980 :  : \\n 29.980 -  29.980 :  : \\n 29.980 -  29.980 :  : \\n 29.980 -  29.980 :  : \\n\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectSpeakers=0\n",
    "filename = \"/tmp/bytes.wav\"\n",
    "results=model.transcribe(filename, word_timestamps=True)\n",
    "txt =\"\"\n",
    "for t in results.get('segments', []):\n",
    "    speaker=\"\"\n",
    "    if ( detectSpeakers):\n",
    "        speaker = who(data, t['start'], t['end'], **kwargs)\n",
    "    o=f\"{t['start']:-7.3f} - {t['end']:7.3f} : {speaker} : {t['text']}\"\n",
    "    txt += o + \"\\n\"\n",
    "ret = dict(file=filename, trans= results['text'], segs=txt)\n",
    "ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 11\u001b[0m\n\u001b[1;32m      4\u001b[0m transcript \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtranscribe(\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#word_timestamps=True,\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     audio\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp/bytes.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m segment \u001b[38;5;129;01min\u001b[39;00m transcript[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegments\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[0;32m---> 11\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[43msegment\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwords\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'words'"
     ]
    }
   ],
   "source": [
    "#pip install openai-whisper\n",
    "import whisper\n",
    "model = whisper.load_model(\"base\")\n",
    "transcript = model.transcribe(\n",
    "    word_timestamps=True,\n",
    "    audio=\"/tmp/bytes.wav\"\n",
    ")\n",
    "for segment in transcript['segments']:\n",
    "    \n",
    "    print(''.join(f\"{word['word']}[{word['start']}/{word['end']}]\" \n",
    "                    for word in segment['words']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"../whispermod.py\"\n",
    "from mangorest.mango import webapi \n",
    "import colabexts\n",
    "from colabexts import jcommon\n",
    "from pytube import YouTube\n",
    "import whisper,  os, datetime, librosa, io, soundfile, sys, hashlib\n",
    "import threading\n",
    "import numpy as np\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "def splitIntoParas(tr, nLinesPerPara=4):\n",
    "    n= nLinesPerPara\n",
    "    l=tr.get('segments', [])\n",
    "    ret = \"\"\n",
    "    for i,j in enumerate(l[::n]):\n",
    "        a, b = i*n, i*n + n\n",
    "        o = \"\".join([j['text'] for j in l[a:b]])\n",
    "        ret += o.strip() + \"\\n\\n\";\n",
    "        #print(f'{a}-{b} {o} \\n')\n",
    "        \n",
    "    return ret\n",
    "#-----------------------------------------------------------------------------------\n",
    "def who(data, start=0, end=None, **kwargs):\n",
    "    try:\n",
    "        import scribe.notebooks.speaker as speaker\n",
    "        top3, tops = speaker.whoisInAudio1(data, top=3, start=start, end=end, **kwargs  )\n",
    "        ret =  { \n",
    "            'top3'    : \";\".join(top3[::-1]) ,\n",
    "            'topScore': \"\"+str(tops)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: \" , e)\n",
    "        ret = {'top3': \";;\", 'topScore': 0}\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
