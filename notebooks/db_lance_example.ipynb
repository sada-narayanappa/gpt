{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LANCEDB EXAMPLE\n",
    "\n",
    "Precondition to run the examples:\n",
    "Install and run OLLAMA and pull llama3.2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully stored in LanceDB.\n",
      "Sample Data in LanceDB:\n",
      "   id                                               text  \\\n",
      "0   1   LanceDB is a fast and efficient vector database.   \n",
      "1   2          OLLAMA makes it easy to run LLMs locally.   \n",
      "2   3  Combining LLMs with LanceDB enables efficient ...   \n",
      "\n",
      "                                              vector  \n",
      "0  [-1.8399125, -0.23122776, -2.9665627, 0.381641...  \n",
      "1  [-2.5748787, 0.18139988, -2.1380749, -1.418047...  \n",
      "2  [-2.179902, 0.93134046, -1.9709134, -0.7056500...  \n",
      "\n",
      "Top Results:\n",
      "Rank 1:\n",
      "ID: 1\n",
      "Text: LanceDB is a fast and efficient vector database.\n",
      "Distance: 12211.1396484375\n",
      "\n",
      "Rank 2:\n",
      "ID: 3\n",
      "Text: Combining LLMs with LanceDB enables efficient search.\n",
      "Distance: 12429.2587890625\n",
      "\n",
      "Rank 3:\n",
      "ID: 2\n",
      "Text: OLLAMA makes it easy to run LLMs locally.\n",
      "Distance: 13213.962890625\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>vector</th>\n",
       "      <th>_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>LanceDB is a fast and efficient vector database.</td>\n",
       "      <td>[-1.8399125, -0.23122776, -2.9665627, 0.381641...</td>\n",
       "      <td>12211.139648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Combining LLMs with LanceDB enables efficient ...</td>\n",
       "      <td>[-2.179902, 0.93134046, -1.9709134, -0.7056500...</td>\n",
       "      <td>12429.258789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>OLLAMA makes it easy to run LLMs locally.</td>\n",
       "      <td>[-2.5748787, 0.18139988, -2.1380749, -1.418047...</td>\n",
       "      <td>13213.962891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  \\\n",
       "0   1   LanceDB is a fast and efficient vector database.   \n",
       "1   3  Combining LLMs with LanceDB enables efficient ...   \n",
       "2   2          OLLAMA makes it easy to run LLMs locally.   \n",
       "\n",
       "                                              vector     _distance  \n",
       "0  [-1.8399125, -0.23122776, -2.9665627, 0.381641...  12211.139648  \n",
       "1  [-2.179902, 0.93134046, -1.9709134, -0.7056500...  12429.258789  \n",
       "2  [-2.5748787, 0.18139988, -2.1380749, -1.418047...  13213.962891  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import requests, lancedb, pandas as pd\n",
    "from typing import List\n",
    "\n",
    "LANCEDB_LOCATION = \"./LANCEDB/\"\n",
    "MODEL= \"ollama3.2\"\n",
    "# --------------------------------------------------------------------------------\n",
    "# Function to get embedding using OLLAMA API\n",
    "# Generate embeddings for a given text using the OLLAMA API.\n",
    "#\n",
    "def get_ollama_embedding(text: str, model: str =MODEL) -> List[float]:\n",
    "    url = \"http://localhost:11434/api/embeddings\"\n",
    "    payload = {\"model\": model, \"prompt\": text}\n",
    "    response = requests.post(url, json=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        embedding = response.json().get(\"embedding\", [])\n",
    "        return embedding\n",
    "    else:\n",
    "        raise Exception(f\"Failed to get embedding: {response.text}\")\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Load your data\n",
    "#\n",
    "def load_example_data():\n",
    "    return [\n",
    "        {\"id\": 1, \"text\": \"LanceDB is a fast and efficient vector database.\"},\n",
    "        {\"id\": 2, \"text\": \"OLLAMA makes it easy to run LLMs locally.\"},\n",
    "        {\"id\": 3, \"text\": \"Combining LLMs with LanceDB enables efficient search.\"}\n",
    "    ]\n",
    "# --------------------------------------------------------------------------------\n",
    "# Function to search LanceDB table for similar embeddings\n",
    "# Search the LanceDB table for the closest embeddings to the query text.\n",
    "#\n",
    "def lancedb_search(query_text: str, top_k: int = 3, table=\"test\", model=MODEL ):\n",
    "\n",
    "    # Generate embedding for the query text\n",
    "    query_embedding = get_ollama_embedding(query_text, model=model )\n",
    "\n",
    "    \n",
    "    db = lancedb.connect(LANCEDB_LOCATION)  # Path to your LanceDB directory\n",
    "    table = db.open_table(table)    # Open the embeddings table\n",
    "\n",
    "\n",
    "    # Perform similarity search\n",
    "    results = table.search(query_embedding).limit(top_k).to_pandas()\n",
    "    #table.search(query).limit(top_k).to_list()\n",
    "\n",
    "\n",
    "    # Display the results\n",
    "    print(\"\\nTop Results:\")\n",
    "    for idx, row in results.iterrows():\n",
    "        print(f\"Rank {idx+1}:\")\n",
    "        print(f\"ID: {row['id']}\")\n",
    "        print(f\"Text: {row['text']}\")\n",
    "        print(f\"Distance: {row['_distance']}\\n\")\n",
    "    \n",
    "    return results\n",
    "# --------------------------------------------------------------------------------\n",
    "# Main function to create embeddings and store in LanceDB\n",
    "#\n",
    "def lancedb_load(model=MODEL, table= \"test\"):\n",
    "    data = load_example_data()\n",
    "\n",
    "    # Generate embeddings\n",
    "    for item in data:\n",
    "        item[\"vector\"] = get_ollama_embedding(item[\"text\"], model=model)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Define LanceDB schema\n",
    "    # table_data = [\n",
    "    #    {\"id\": row[\"id\"], \"text\": row[\"text\"], \"vector\": row[\"vector\"]}\n",
    "    #    for _, row in df.iterrows()\n",
    "    # ]\n",
    "    table_data = df.to_dict(orient='records')\n",
    "\n",
    "    # Initialize LanceDB\n",
    "    db = lancedb.connect(LANCEDB_LOCATION)  # Directory where the DB will be stored\n",
    "    table = db.create_table(table, data=table_data, mode=\"overwrite\")\n",
    "    print(\"Data successfully stored in LanceDB.\")\n",
    "\n",
    "    # Query to verify\n",
    "    print(\"Sample Data in LanceDB:\")\n",
    "    print(table.to_pandas())\n",
    "    return df\n",
    "\n",
    "df = lancedb_load()\n",
    "lancedb_search(\"what is an efficient db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
