{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "'''\n",
    "from simple_diarizer.diarizer import Diarizer\n",
    "\n",
    "diarization = Diarizer(embed_model='xvec', cluster_method='sc')\n",
    "segments = diarization.diarize(\"/tmp/test_multiple.wav\", num_speakers=2)\n",
    "segments\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, torch\n",
    "device = \"cpu\"\n",
    "if (torch.cuda.is_available() ):\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available() and platform.processor() =='arm':\n",
    "    device = \"mps\"\n",
    "    \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pyannote pipeline from models/pyannote.yml... CWD: /opt/LMCO/git/notebooks/DS/gpt/notebooks\n",
      "Changing working directory to /opt/LMCO/git/notebooks/DS/gpt/notebooks\n",
      "Changing working directory back to /opt/LMCO/git/notebooks/DS/gpt/notebooks\n"
     ]
    }
   ],
   "source": [
    "#%%writefile \"../diarize.py\"\n",
    "#!/usr/bin/env python\n",
    "import os, torch\n",
    "from pyannote.audio import Pipeline\n",
    "from pathlib import Path\n",
    "from mangorest.mango import webapi \n",
    "import platform; \n",
    "\n",
    "device = \"cpu\"\n",
    "if (torch.cuda.is_available() ):\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available() and platform.processor() =='arm':\n",
    "    device = \"mps\"\n",
    "# -----------------------------------------------------------------------------\n",
    "diarizer = None\n",
    "def getdiarizer():\n",
    "    global diarizer \n",
    "    if ( diarizer is not None):\n",
    "        return diarizer\n",
    "\n",
    "    atoken = \"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\"\n",
    "    model  = \"pyannote/speaker-diarization-3.0\"\n",
    "    #pipeline = Pipeline.from_pretrained(model, use_auth_token=atoken)\n",
    "    pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.0\")\n",
    "    pipeline.to(torch.device(device) )\n",
    "    \n",
    "    diarizer = pipeline\n",
    "    return diarizer\n",
    "\n",
    "''' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "Searches for the directory containg this app\n",
    "'''\n",
    "def searchfor(loc=\"models/pyannote.yml\", max_depth=2):\n",
    "    if ( os.path.exists(loc)):\n",
    "        return loc\n",
    "    cwd = Path.cwd().resolve() \n",
    "    for i in range(max_depth):\n",
    "        loc= f\"../{loc}\"\n",
    "        print(f\"Trying {loc} - {cwd} \")\n",
    "        if ( os.path.exists(loc) ):\n",
    "            return loc\n",
    "    return \"\"\n",
    "    \n",
    "def getdiarizerLocal(path_to_config: str | Path) -> Pipeline:\n",
    "    global diarizer \n",
    "    if ( diarizer is not None):\n",
    "        return diarizer\n",
    "    path_to_config = Path(path_to_config)\n",
    "    cwd = Path.cwd().resolve()  # store current working directory\n",
    "\n",
    "    print(f\"Loading pyannote pipeline from {path_to_config}... CWD: {cwd}\")\n",
    "    # the paths in the config are relative to the current working directory\n",
    "    # so we need to change the working directory to the model path\n",
    "    # and then change it back\n",
    "\n",
    "    # first .parent is the folder of the config, second .parent is the folder containing the 'models' folder\n",
    "    cd_to = path_to_config.parent.parent.resolve()\n",
    "    print(f\"Changing working directory to {cd_to}\")\n",
    "    os.chdir(cd_to)\n",
    "\n",
    "    pipeline = Pipeline.from_pretrained(path_to_config)\n",
    "    print(f\"Changing working directory back to {cwd}\")\n",
    "    os.chdir(cwd)\n",
    "\n",
    "    pipeline.to(torch.device(device) )\n",
    "    diarizer = pipeline\n",
    "    return diarizer\n",
    "\n",
    "path=searchfor()\n",
    "diarizer=None\n",
    "if ( path ):\n",
    "    diarizer = getdiarizerLocal(path)\n",
    "else:\n",
    "    print(\"Model not found\")\n",
    "# -----------------------------------------------------------------------------\n",
    "'''\n",
    "Diarize first file sent in\n",
    "'''\n",
    "@webapi(\"/scribe/diarize/\")\n",
    "def diarize(request=None,file=\"/tmp/test_multiple.wav\", nspeakers=None ):\n",
    "    if ( request):\n",
    "        for f in request.FILES.getlist('file'):\n",
    "            content = f.read()\n",
    "            file = f\"/tmp/{str(f)}\"\n",
    "            with open(file, \"wb\") as f:\n",
    "                f.write(content)\n",
    "    \n",
    "    diarization = diarizer(file, num_speakers=nspeakers)\n",
    "    ret = \"[\\n\"\n",
    "    for segment, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        #print(f'Speaker \"{speaker}\" - \"{segment}\"')\n",
    "        id = int(speaker.split('_')[1])\n",
    "        ret +=f'{{start: {segment.start}, end: {segment.end}, label: {id} }},\\n'\n",
    "        \n",
    "    ret += \"]\"\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.core import Segment\n",
    "\n",
    "class PyanWhisper:\n",
    "    PUNC_SENT_END = ['.', '?', '!']\n",
    "        \n",
    "    def diarize_text(transcribe_res, diarization_result):\n",
    "        timestamp_texts = PyanWhisper.get_text_with_timestamp(transcribe_res)\n",
    "        spk_text = PyanWhisper.add_speaker_info_to_text(timestamp_texts, diarization_result)\n",
    "        res_processed = PyanWhisper.merge_sentence(spk_text)\n",
    "        return res_processed\n",
    "\n",
    "    def get_text_with_timestamp(transcribe_res):\n",
    "        timestamp_texts = []\n",
    "        for item in transcribe_res['segments']:\n",
    "            start = item['start']\n",
    "            end = item['end']\n",
    "            text = item['text']\n",
    "            timestamp_texts.append((Segment(start, end), text))\n",
    "        return timestamp_texts\n",
    "    \n",
    "    def add_speaker_info_to_text(timestamp_texts, ann):\n",
    "        spk_text = []\n",
    "        for seg, text in timestamp_texts:\n",
    "            spk = ann.crop(seg).argmax()\n",
    "            spk_text.append((seg, spk, text))\n",
    "        return spk_text\n",
    "    \n",
    "    def merge_cache(text_cache):\n",
    "        sentence = ''.join([item[-1] for item in text_cache])\n",
    "        spk = text_cache[0][1]\n",
    "        start = text_cache[0][0].start\n",
    "        end = text_cache[-1][0].end\n",
    "        return Segment(start, end), spk, sentence\n",
    "    \n",
    "    def merge_sentence(spk_text):\n",
    "        merged_spk_text = []\n",
    "        pre_spk = None\n",
    "        text_cache = []\n",
    "        for seg, spk, text in spk_text:\n",
    "            if spk != pre_spk and pre_spk is not None and len(text_cache) > 0:\n",
    "                merged_spk_text.append(PyanWhisper.merge_cache(text_cache))\n",
    "                text_cache = [(seg, spk, text)]\n",
    "                pre_spk = spk\n",
    "            elif text[-1] in PyanWhisper.PUNC_SENT_END:\n",
    "                text_cache.append((seg, spk, text))\n",
    "                merged_spk_text.append(PyanWhisper.merge_cache(text_cache))\n",
    "                text_cache = []\n",
    "                pre_spk = spk\n",
    "            else:\n",
    "                text_cache.append((seg, spk, text))\n",
    "                pre_spk = spk\n",
    "        if len(text_cache) > 0:\n",
    "            merged_spk_text.append(PyanWhisper.merge_cache(text_cache))\n",
    "        return merged_spk_text\n",
    "\n",
    "    def write_to_txt(spk_sent, file):\n",
    "        with open(file, 'w') as fp:\n",
    "            for seg, spk, sentence in spk_sent:\n",
    "                line = f'{seg.start:.2f} {seg.end:.2f} {spk} {sentence}\\n'\n",
    "                fp.write(line)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2.88G/2.88G [00:50<00:00, 61.7MiB/s]\n",
      "/Users/snarayan/venv/py312/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "#-----------------------------models-----------------------------------------------------------------\n",
    "device = \"cpu\"\n",
    "if (torch.cuda.is_available() ):\n",
    "    device = \"cuda\"\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = \"mps\"\n",
    "#-----------------------------------------------------------------------------------\n",
    "import threading\n",
    "mutex        = threading.Lock()\n",
    "transcriber  = None\n",
    "def getTranscriber():\n",
    "    global transcriber, mutex\n",
    "    \n",
    "    if transcriber is None:\n",
    "        mutex.acquire()\n",
    "        if transcriber is None:\n",
    "            transcriber = whisper.load_model(\"base\", device=device)\n",
    "        mutex.release()   \n",
    "    return transcriber\n",
    "\n",
    "file=\"/tmp/test_multiple.wav\"\n",
    "\n",
    "#t=whisper.load_model(\"large\", device=device)\n",
    "transcription = t.transcribe(file)\n",
    "diarization = diarizer(file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'speaker': 'SPEAKER_01', 'text': ''},\n",
       " {'speaker': 'SPEAKER_02', 'text': ''},\n",
       " {'speaker': 'SPEAKER_01', 'text': ''},\n",
       " {'speaker': 'SPEAKER_02', 'text': \" I didn't know you were there.\"},\n",
       " {'speaker': 'SPEAKER_01', 'text': ' Neither did I.'},\n",
       " {'speaker': 'SPEAKER_02',\n",
       "  'text': ' Okay, I thought, you know, I heard a beep.  This is Diane in New Jersey.'},\n",
       " {'speaker': 'SPEAKER_00', 'text': ''},\n",
       " {'speaker': 'SPEAKER_00',\n",
       "  'text': \" And I'm Sheila in Texas, originally from Chicago.\"},\n",
       " {'speaker': 'SPEAKER_02',\n",
       "  'text': \" Oh, I'm originally from Chicago also.  I'm in New Jersey now, though.\"},\n",
       " {'speaker': 'SPEAKER_00', 'text': ''},\n",
       " {'speaker': 'SPEAKER_00',\n",
       "  'text': \" Well, there isn't that much difference.  At least, you know, they all call me a Yankee down here, so we'll kind of say.\"},\n",
       " {'speaker': 'SPEAKER_02',\n",
       "  'text': \" Oh, I don't hear that in New Jersey now.\"}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Align Whisper transcription with speaker segments\n",
    "result = []\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    segment_texts = [\n",
    "        t[\"text\"] for t in transcription[\"segments\"]\n",
    "        if t[\"start\"] >= turn.start and t[\"end\"] <= turn.end\n",
    "    ]\n",
    "    result.append({\"speaker\": speaker, \"text\": \" \".join(segment_texts)})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0: 6.96 :  Hello?\n",
      "7.42: 7.86 :  Hello.\n",
      "8.3: 8.78 :  Oh, hello.\n",
      "8.88: 9.78 :  I didn't know you were there.\n",
      "10.0: 10.64 :  Neither did I.\n",
      "10.64: 12.44 :  Okay, I thought, you know, I heard a beep.\n",
      "12.52: 14.0 :  This is Diane in New Jersey.\n",
      "14.36: 17.6 :  And I'm Sheila in Texas, originally from Chicago.\n",
      "18.06: 20.04 :  Oh, I'm originally from Chicago also.\n",
      "20.04: 21.46 :  I'm in New Jersey now, though.\n",
      "21.86: 23.86 :  Well, there isn't that much difference.\n",
      "24.0: 28.36 :  At least, you know, they all call me a Yankee down here, so we'll kind of say.\n",
      "28.38: 29.86 :  Oh, I don't hear that in New Jersey now.\n"
     ]
    }
   ],
   "source": [
    "for t in transcription['segments']:\n",
    "    print(f'{t[\"start\"]}: {t[\"end\"]} : {t[\"text\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "{start: 6.730343750000001, end: 7.16909375, label: 1 }\n",
      "{start: 7.16909375, end: 7.185968750000001, label: 2 }\n",
      "{start: 7.59096875, end: 8.316593750000003, label: 1 }\n",
      "{start: 8.316593750000003, end: 9.919718750000001, label: 2 }\n",
      "{start: 9.919718750000001, end: 10.93221875, label: 1 }\n",
      "{start: 10.45971875, end: 14.745968750000003, label: 2 }\n",
      "{start: 10.93221875, end: 10.98284375, label: 0 }\n",
      "{start: 14.30721875, end: 17.88471875, label: 0 }\n",
      "{start: 18.01971875, end: 21.512843750000002, label: 2 }\n",
      "{start: 18.15471875, end: 18.44159375, label: 0 }\n",
      "{start: 21.765968750000003, end: 28.49909375, label: 0 }\n",
      "{start: 27.85784375, end: 29.96721875, label: 2 }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "res=diarize(None, file)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \" Hello? Hello. Oh, hello. I didn't know you were there. Neither did I. Okay, I thought, you know, I heard a beep. This is Diane in New Jersey. And I'm Sheila in Texas, originally from Chicago. Oh, I'm originally from Chicago also. I'm in New Jersey now, though. Well, there isn't that much difference. At least, you know, they all call me a Yankee down here, so we'll kind of say. Oh, I don't hear that in New Jersey now.\",\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 6.96,\n",
       "   'text': ' Hello?',\n",
       "   'tokens': [50365, 2425, 30, 50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17604375566755023,\n",
       "   'compression_ratio': 1.7004048582995952,\n",
       "   'no_speech_prob': 0.03709212318062782},\n",
       "  {'id': 1,\n",
       "   'seek': 0,\n",
       "   'start': 7.42,\n",
       "   'end': 7.86,\n",
       "   'text': ' Hello.',\n",
       "   'tokens': [50736, 2425, 13, 50758],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17604375566755023,\n",
       "   'compression_ratio': 1.7004048582995952,\n",
       "   'no_speech_prob': 0.03709212318062782},\n",
       "  {'id': 2,\n",
       "   'seek': 0,\n",
       "   'start': 8.3,\n",
       "   'end': 8.78,\n",
       "   'text': ' Oh, hello.',\n",
       "   'tokens': [50780, 876, 11, 7751, 13, 50804],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17604375566755023,\n",
       "   'compression_ratio': 1.7004048582995952,\n",
       "   'no_speech_prob': 0.03709212318062782},\n",
       "  {'id': 3,\n",
       "   'seek': 0,\n",
       "   'start': 8.88,\n",
       "   'end': 9.78,\n",
       "   'text': \" I didn't know you were there.\",\n",
       "   'tokens': [50809, 286, 994, 380, 458, 291, 645, 456, 13, 50854],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17604375566755023,\n",
       "   'compression_ratio': 1.7004048582995952,\n",
       "   'no_speech_prob': 0.03709212318062782},\n",
       "  {'id': 4,\n",
       "   'seek': 0,\n",
       "   'start': 10.0,\n",
       "   'end': 10.64,\n",
       "   'text': ' Neither did I.',\n",
       "   'tokens': [50865, 23956, 630, 286, 13, 50897],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17604375566755023,\n",
       "   'compression_ratio': 1.7004048582995952,\n",
       "   'no_speech_prob': 0.03709212318062782},\n",
       "  {'id': 5,\n",
       "   'seek': 0,\n",
       "   'start': 10.64,\n",
       "   'end': 12.44,\n",
       "   'text': ' Okay, I thought, you know, I heard a beep.',\n",
       "   'tokens': [50897,\n",
       "    1033,\n",
       "    11,\n",
       "    286,\n",
       "    1194,\n",
       "    11,\n",
       "    291,\n",
       "    458,\n",
       "    11,\n",
       "    286,\n",
       "    2198,\n",
       "    257,\n",
       "    28678,\n",
       "    13,\n",
       "    50987],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17604375566755023,\n",
       "   'compression_ratio': 1.7004048582995952,\n",
       "   'no_speech_prob': 0.03709212318062782},\n",
       "  {'id': 6,\n",
       "   'seek': 0,\n",
       "   'start': 12.52,\n",
       "   'end': 14.0,\n",
       "   'text': ' This is Diane in New Jersey.',\n",
       "   'tokens': [50991, 639, 307, 30460, 294, 1873, 16601, 13, 51065],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17604375566755023,\n",
       "   'compression_ratio': 1.7004048582995952,\n",
       "   'no_speech_prob': 0.03709212318062782},\n",
       "  {'id': 7,\n",
       "   'seek': 0,\n",
       "   'start': 14.36,\n",
       "   'end': 17.6,\n",
       "   'text': \" And I'm Sheila in Texas, originally from Chicago.\",\n",
       "   'tokens': [51083,\n",
       "    400,\n",
       "    286,\n",
       "    478,\n",
       "    48832,\n",
       "    294,\n",
       "    7885,\n",
       "    11,\n",
       "    7993,\n",
       "    490,\n",
       "    9525,\n",
       "    13,\n",
       "    51245],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17604375566755023,\n",
       "   'compression_ratio': 1.7004048582995952,\n",
       "   'no_speech_prob': 0.03709212318062782},\n",
       "  {'id': 8,\n",
       "   'seek': 0,\n",
       "   'start': 18.06,\n",
       "   'end': 20.04,\n",
       "   'text': \" Oh, I'm originally from Chicago also.\",\n",
       "   'tokens': [51268, 876, 11, 286, 478, 7993, 490, 9525, 611, 13, 51367],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17604375566755023,\n",
       "   'compression_ratio': 1.7004048582995952,\n",
       "   'no_speech_prob': 0.03709212318062782},\n",
       "  {'id': 9,\n",
       "   'seek': 0,\n",
       "   'start': 20.04,\n",
       "   'end': 21.46,\n",
       "   'text': \" I'm in New Jersey now, though.\",\n",
       "   'tokens': [51367, 286, 478, 294, 1873, 16601, 586, 11, 1673, 13, 51438],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17604375566755023,\n",
       "   'compression_ratio': 1.7004048582995952,\n",
       "   'no_speech_prob': 0.03709212318062782},\n",
       "  {'id': 10,\n",
       "   'seek': 0,\n",
       "   'start': 21.86,\n",
       "   'end': 23.86,\n",
       "   'text': \" Well, there isn't that much difference.\",\n",
       "   'tokens': [51458, 1042, 11, 456, 1943, 380, 300, 709, 2649, 13, 51558],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17604375566755023,\n",
       "   'compression_ratio': 1.7004048582995952,\n",
       "   'no_speech_prob': 0.03709212318062782},\n",
       "  {'id': 11,\n",
       "   'seek': 0,\n",
       "   'start': 24.0,\n",
       "   'end': 28.36,\n",
       "   'text': \" At least, you know, they all call me a Yankee down here, so we'll kind of say.\",\n",
       "   'tokens': [51565,\n",
       "    1711,\n",
       "    1935,\n",
       "    11,\n",
       "    291,\n",
       "    458,\n",
       "    11,\n",
       "    436,\n",
       "    439,\n",
       "    818,\n",
       "    385,\n",
       "    257,\n",
       "    13633,\n",
       "    21687,\n",
       "    760,\n",
       "    510,\n",
       "    11,\n",
       "    370,\n",
       "    321,\n",
       "    603,\n",
       "    733,\n",
       "    295,\n",
       "    584,\n",
       "    13,\n",
       "    51783],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17604375566755023,\n",
       "   'compression_ratio': 1.7004048582995952,\n",
       "   'no_speech_prob': 0.03709212318062782},\n",
       "  {'id': 12,\n",
       "   'seek': 0,\n",
       "   'start': 28.38,\n",
       "   'end': 29.86,\n",
       "   'text': \" Oh, I don't hear that in New Jersey now.\",\n",
       "   'tokens': [51784,\n",
       "    876,\n",
       "    11,\n",
       "    286,\n",
       "    500,\n",
       "    380,\n",
       "    1568,\n",
       "    300,\n",
       "    294,\n",
       "    1873,\n",
       "    16601,\n",
       "    586,\n",
       "    13,\n",
       "    51858],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17604375566755023,\n",
       "   'compression_ratio': 1.7004048582995952,\n",
       "   'no_speech_prob': 0.03709212318062782}],\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
