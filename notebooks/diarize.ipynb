{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom simple_diarizer.diarizer import Diarizer\\n\\ndiarization = Diarizer(embed_model=\\'xvec\\', cluster_method=\\'sc\\')\\nsegments = diarization.diarize(\"/tmp/test_multiple.wav\", num_speakers=2)\\nsegments\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "'''\n",
    "from simple_diarizer.diarizer import Diarizer\n",
    "\n",
    "diarization = Diarizer(embed_model='xvec', cluster_method='sc')\n",
    "segments = diarization.diarize(\"/tmp/test_multiple.wav\", num_speakers=2)\n",
    "segments\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../diarize.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"../diarize.py\"\n",
    "#!/usr/bin/env python\n",
    "import os, torch\n",
    "from pathlib import Path\n",
    "from mangorest.mango import webapi \n",
    "import platform; \n",
    "\n",
    "device = \"cpu\"\n",
    "if (torch.cuda.is_available() ):\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available() and platform.processor() =='arm':\n",
    "    device = \"mps\"\n",
    "# -----------------------------------------------------------------------------\n",
    "diarizer = None\n",
    "def getdiarizer():\n",
    "    from pyannote.audio import Pipeline\n",
    "    global diarizer \n",
    "    if ( diarizer is not None):\n",
    "        return diarizer\n",
    "\n",
    "    atoken = \"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\"\n",
    "    model  = \"pyannote/speaker-diarization-3.0\"\n",
    "    #pipeline = Pipeline.from_pretrained(model, use_auth_token=atoken)\n",
    "    pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.0\")\n",
    "    pipeline.to(torch.device(device) )\n",
    "    \n",
    "    diarizer = pipeline\n",
    "    return diarizer\n",
    "\n",
    "''' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "Searches for the directory containg this app\n",
    "'''\n",
    "def searchfor(loc=\"models/pyannote.yml\", max_depth=2):\n",
    "    if ( os.path.exists(loc)):\n",
    "        return loc\n",
    "    cwd = Path.cwd().resolve() \n",
    "    for i in range(max_depth):\n",
    "        loc= f\"../{loc}\"\n",
    "        print(f\"Trying {loc} - {cwd} \")\n",
    "        if ( os.path.exists(loc) ):\n",
    "            return loc\n",
    "    return \"\"\n",
    "    \n",
    "def getdiarizerLocal(path_to_config: str | Path) :\n",
    "    global diarizer \n",
    "    if ( diarizer is not None):\n",
    "        return diarizer\n",
    "    path_to_config = Path(path_to_config)\n",
    "    cwd = Path.cwd().resolve()  # store current working directory\n",
    "\n",
    "    print(f\"Loading pyannote pipeline from {path_to_config}... CWD: {cwd}\")\n",
    "    # the paths in the config are relative to the current working directory\n",
    "    # so we need to change the working directory to the model path\n",
    "    # and then change it back\n",
    "\n",
    "    # first .parent is the folder of the config, second .parent is the folder containing the 'models' folder\n",
    "    cd_to = path_to_config.parent.parent.resolve()\n",
    "    print(f\"Changing working directory to {cd_to}\")\n",
    "    os.chdir(cd_to)\n",
    "\n",
    "    pipeline = Pipeline.from_pretrained(path_to_config)\n",
    "    print(f\"Changing working directory back to {cwd}\")\n",
    "    os.chdir(cwd)\n",
    "\n",
    "    pipeline.to(torch.device(device) )\n",
    "    diarizer = pipeline\n",
    "    return diarizer\n",
    "\n",
    "def testDiarize():\n",
    "    try:\n",
    "        dir = os.path.dirname(__file__)\n",
    "        path= f'{dir}/models/pyannote.yml'\n",
    "    except:\n",
    "        path=\"models/pyannote.yml\"\n",
    "        pass\n",
    "    path=searchfor(path)\n",
    "    diarizer=None\n",
    "    if ( path ):\n",
    "        diarizer = getdiarizerLocal(path)\n",
    "    else:\n",
    "        print(\"Model not found\")\n",
    "# -----------------------------------------------------------------------------\n",
    "'''\n",
    "Diarize first file sent in\n",
    "'''\n",
    "@webapi(\"/scribe/diarize/\")\n",
    "def diarize(request=None,file=\"/tmp/test_multiple.wav\", nspeakers=None, **kwargs ):\n",
    "    print(f\"<============= {file} n={nspeakers} {kwargs}\" )\n",
    "    global diarizer\n",
    "    if ( not diarizer) :\n",
    "        return \"Sorry - diarizer not loaded!\"\n",
    "\n",
    "    if ( request and len(request.FILES) > 0):\n",
    "        for f in request.FILES.getlist('file'):\n",
    "            content = f.read()\n",
    "            file = f\"/tmp/{str(f)}\"\n",
    "            with open(file, \"wb\") as f:\n",
    "                f.write(content)\n",
    "            break; #lets do one file at a time now\n",
    "    elif (type(file) == str):\n",
    "        pass # Cool this is what we wanted\n",
    "    else:\n",
    "        pass\n",
    "        # filename=\"/tmp/diarize.wav\"\n",
    "        # with open(filename, \"wb\") as f:\n",
    "        #     f.write(file)\n",
    "        # file = filename\n",
    "\n",
    "    print(f\"<============= {file} n={nspeakers} {kwargs}\" )\n",
    "    diarization = diarizer(file, num_speakers= nspeakers or None )\n",
    "    ret = []\n",
    "    for segment, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        #print(f'Speaker \"{speaker}\" - \"{segment}\"')\n",
    "        id = int(speaker.split('_')[1])\n",
    "        e = dict(start=segment.start, end = segment.end, label=id)\n",
    "        ret.append(e)\n",
    "        \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<============= /tmp/blob.wav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[\\n{start: 6.730343750000001, end: 7.16909375, label: 1 },\\n{start: 7.16909375, end: 7.185968750000001, label: 2 },\\n{start: 7.59096875, end: 8.316593750000003, label: 1 },\\n{start: 8.316593750000003, end: 9.919718750000001, label: 2 },\\n{start: 9.919718750000001, end: 10.93221875, label: 1 },\\n{start: 10.45971875, end: 14.745968750000003, label: 2 },\\n{start: 10.93221875, end: 10.98284375, label: 0 },\\n{start: 14.30721875, end: 17.88471875, label: 0 },\\n{start: 18.01971875, end: 21.512843750000002, label: 2 },\\n{start: 18.15471875, end: 18.44159375, label: 0 },\\n{start: 21.765968750000003, end: 28.49909375, label: 0 },\\n{start: 27.85784375, end: 29.96721875, label: 2 },\\n]'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file=\"/tmp/blob.wav\"\n",
    "diarization = diarize(None,file, num_speakers=None)\n",
    "diarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE REView and delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.core import Segment\n",
    "\n",
    "class PyanWhisper:\n",
    "    PUNC_SENT_END = ['.', '?', '!']\n",
    "        \n",
    "    def diarize_text(transcribe_res, diarization_result):\n",
    "        timestamp_texts = PyanWhisper.get_text_with_timestamp(transcribe_res)\n",
    "        spk_text = PyanWhisper.add_speaker_info_to_text(timestamp_texts, diarization_result)\n",
    "        res_processed = PyanWhisper.merge_sentence(spk_text)\n",
    "        return res_processed\n",
    "\n",
    "    def get_text_with_timestamp(transcribe_res):\n",
    "        timestamp_texts = []\n",
    "        for item in transcribe_res['segments']:\n",
    "            start = item['start']\n",
    "            end = item['end']\n",
    "            text = item['text']\n",
    "            timestamp_texts.append((Segment(start, end), text))\n",
    "        return timestamp_texts\n",
    "    \n",
    "    def add_speaker_info_to_text(timestamp_texts, ann):\n",
    "        spk_text = []\n",
    "        for seg, text in timestamp_texts:\n",
    "            spk = ann.crop(seg).argmax()\n",
    "            spk_text.append((seg, spk, text))\n",
    "        return spk_text\n",
    "    \n",
    "    def merge_cache(text_cache):\n",
    "        sentence = ''.join([item[-1] for item in text_cache])\n",
    "        spk = text_cache[0][1]\n",
    "        start = text_cache[0][0].start\n",
    "        end = text_cache[-1][0].end\n",
    "        return Segment(start, end), spk, sentence\n",
    "    \n",
    "    def merge_sentence(spk_text):\n",
    "        merged_spk_text = []\n",
    "        pre_spk = None\n",
    "        text_cache = []\n",
    "        for seg, spk, text in spk_text:\n",
    "            if spk != pre_spk and pre_spk is not None and len(text_cache) > 0:\n",
    "                merged_spk_text.append(PyanWhisper.merge_cache(text_cache))\n",
    "                text_cache = [(seg, spk, text)]\n",
    "                pre_spk = spk\n",
    "            elif text[-1] in PyanWhisper.PUNC_SENT_END:\n",
    "                text_cache.append((seg, spk, text))\n",
    "                merged_spk_text.append(PyanWhisper.merge_cache(text_cache))\n",
    "                text_cache = []\n",
    "                pre_spk = spk\n",
    "            else:\n",
    "                text_cache.append((seg, spk, text))\n",
    "                pre_spk = spk\n",
    "        if len(text_cache) > 0:\n",
    "            merged_spk_text.append(PyanWhisper.merge_cache(text_cache))\n",
    "        return merged_spk_text\n",
    "\n",
    "    def write_to_txt(spk_sent, file):\n",
    "        with open(file, 'w') as fp:\n",
    "            for seg, spk, sentence in spk_sent:\n",
    "                line = f'{seg.start:.2f} {seg.end:.2f} {spk} {sentence}\\n'\n",
    "                fp.write(line)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/e346104/venv/py312/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<pyannote.core.annotation.Annotation at 0x33ea5f5f0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import whisper, torch\n",
    "#-----------------------------models-----------------------------------------------------------------\n",
    "device = \"cpu\"\n",
    "if (torch.cuda.is_available() ):\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "#-----------------------------------------------------------------------------------\n",
    "import threading\n",
    "mutex        = threading.Lock()\n",
    "transcriber  = None\n",
    "def getTranscriber():\n",
    "    global transcriber, mutex\n",
    "    \n",
    "    if transcriber is None:\n",
    "        mutex.acquire()\n",
    "        if transcriber is None:\n",
    "            transcriber = whisper.load_model(\"base\", device=device)\n",
    "        mutex.release()   \n",
    "    return transcriber\n",
    "\n",
    "file=\"/tmp/test_multiple.wav\"\n",
    "\n",
    "#t=whisper.load_model(\"base\")#, device=device)\n",
    "transcription = t.transcribe(file)\n",
    "diarization = diarizer(file=file, num_speakers=2)\n",
    "diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
